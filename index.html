<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>NVIDIA GPU Roadmap</title>
  <style>
    * {
      box-sizing: border-box;
      font-family: 'Segoe UI', Arial, sans-serif;
    }
    
    body {
      margin: 0;
      padding: 40px;
      background-color: #f9f9f9;
    }
    
    .grid-container {
      background-color: white;
      border-radius: 4px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.08);
      padding: 10px;
      max-width: 1300px;
      margin: 0 auto;
    }
    
    /* Table styles */
    table {
      border-collapse: collapse;
      width: 100%;
      font-size: 13px;
    }
    
    th, td {
      padding: 6px 4px;
      text-align: center;
      border: 1px solid #c1c1c1;
    }
    
    tr:nth-child(even) {
      background-color: #f8f8f8;
    }
    
    /* Row styling */
    .header-row {
      background-color: #134f5c;
      color: white;
      font-weight: bold;
    }
    
    .header-row th {
      border: 1px solid #0c3741;
    }
    
    .category-row {
      font-weight: bold;
      text-align: center;
      background-color: #134f5c;
    }
    
    .category-row td {
      text-align: center;
      padding-left: 15px;
    }
    
    .nvidia-row {
      background-color: #efefef;
      font-weight: bold;
    }
    
    /* First column styling */
    td:first-child {
      font-weight: bold;
      text-align: center;
      background-color: #f2f2f2;
      padding-left: 15px;
    }

    .category-row td:first-child {
        background-color: #d9d9d9; /* or whatever color you want for category rows */
    }
    
    /* Tooltip styles */
    .tooltip {
      position: relative;
      display: inline-block;
      border-bottom: 1px dotted;
      cursor: help;
    }

        /* Tooltip styles */
    .tooltip.important {
      color: #0c6478;
      font-weight: bold;
    }
    
    .tooltip .tooltiptext {
      visibility: hidden;
      width: 280px;
      background-color: #2c3e50;
      color: #fff;
      text-align: left;
      border-radius: 6px;
      padding: 12px;
      position: absolute;
      z-index: 1;
      bottom: 125%;
      left: 50%;
      margin-left: -140px;
      opacity: 0;
      transition: opacity 0.3s, transform 0.3s;
      transform: translateY(10px);
      box-shadow: 0 4px 15px rgba(0,0,0,0.2);
      font-weight: normal;
      font-size: 0.92em;
      line-height: 1.5;
    }

    .tooltip .tooltiptext::after {
      content: "";
      position: absolute;
      top: 100%;
      left: 50%;
      margin-left: -8px;
      border-width: 8px;
      border-style: solid;
      border-color: #2c3e50 transparent transparent transparent;
    }
    
    .tooltip:hover .tooltiptext {
      visibility: visible;
      opacity: 1;
      transform: translateY(0);
    }
    
    .tooltip .tooltiptext.active {
      visibility: visible;
      opacity: 1;
      transform: translateY(0);
    }

    /* Source citation styling */
    .source-citation {
      font-size: 11px;
      color: #666;
      text-align: left;
      margin-top: 20px;
      padding-top: 10px;
      border-top: 1px solid #eee;
    }
    
    .source-citation a {
      color: #0c6478;
      text-decoration: none;
    }
    
    .source-citation a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <div class="grid-container">
    <table>
      <thead>
        <tr class="header-row">
          <th></th>
          <th>2022</th>
          <th>2023</th>
          <th>2024</th>
          <th colspan="2">2025</th>
          <th>2026</th>
          <th>2027</th>
        </tr>
      </thead>
      <tbody>
        <tr class="category-row">
            <td colspan="8">Chip and Package Level</td>
          </tr>

        <tr class="nvidia-row">
          <td>Architecture</td>
          <td colspan="2">
            <span class="tooltip">Hopper
              <span class="tooltiptext">NVIDIA's compute architecture named after Grace Hopper, introduced in 2022. Featuring significant improvements in AI performance with Transformer Engine and the first FP8 precision for AI acceleration.</span>
            </span>
          </td>
          <td colspan="3">
            <span class="tooltip">Blackwell
              <span class="tooltiptext">NVIDIA's architecture named after statistician David Blackwell, featuring a multi-chip module design with two GPU dies and a focus on AI/ML workloads with enhanced performance per watt compared to Hopper.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">Rubin
              <span class="tooltiptext">NVIDIA's projected next-generation architecture after Blackwell, named after astronomer Vera Rubin. Expected to feature TSMC's 3nm process technology and significant architectural advances.</span>
            </span>
          </td>
        </tr>
        
        <tr>
          <td>Accelerator</td>
          <td>
            <span class="tooltip">H100 (SXM)
              <span class="tooltiptext">NVIDIA's flagship Hopper GPU designed for high-performance computing and AI workloads, featuring 80 GB HBM3 memory.</span>
            </span>
          </td>
          <td>
            <span class="tooltip">H200
              <span class="tooltiptext">Enhanced version of Hopper architecture with upgraded memory (141 GB HBM3E) and higher memory bandwidth, designed for AI training and inference workloads.</span>
            </span>
          </td>
          <td>
            <span class="tooltip">B200/ GB200
              <span class="tooltiptext">Blackwell GPU (B200) and its CPU-integrated version (GB200). First dual-die (using two connected silicon chips in one package) GPU design from NVIDIA, offering gains in AI compute performance and energy efficiency.</span>
            </span>
          </td>
          <td>
            <span class="tooltip"> GB300 (Ultra)
              <span class="tooltiptext">Enhanced Blackwell generation GPU with 'Ultra' configuration, featuring higher performance and memory capacity compared to GB200.</span>
            </span>
          </td>
          <td>
            <span class="tooltip">B300
              <span class="tooltiptext">Single-die variant of the B300 architecture, designed for more cost-effective deployments while maintaining Blackwell architectural advantages.</span>
            </span>
          </td>
          <td>
            <span class="tooltip">VR200
              <span class="tooltiptext">First-generation Rubin architecture GPU, named for Vera Rubin. Expected to deliver substantial performance increases over the Blackwell generation.</span>
            </span>
          </td>
          <td>
            <span class="tooltip">VR300 (Ultra)
              <span class="tooltiptext">Enhanced Rubin architecture with 'Ultra' configuration, featuring 4 GPU dies and highest performance in the NVIDIA data center GPU lineup.</span>
            </span>
          </td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">GPU TDP
              <span class="tooltiptext">Thermal Design Power, measured in watts. Represents the maximum amount of heat generated by the GPU that the cooling system is designed to dissipate.</span>
            </span>
          </td>
          <td>700 W</td>
          <td>700 W</td>
          <td>700 / 1,200 W</td>
          <td>1,400 W</td>
          <td>600 W</td>
          <td>1,800 W</td>
          <td>3,600 W</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">Foundry node
              <span class="tooltiptext">Refers to a specific semiconductor manufacturing technology generation. Historically, the number (e.g., "3NP", "4NP") indicated the minimum transistor length that could be manufactured. Today, these numbers are primarily marketing terms that no longer correspond to any single physical dimension on the chip. Modern process nodes (like "5 nm," and "3 nm") represent an advancement in manufacturing technology that generally delivers more transistors per area, better performance, and improved energy efficiency.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">4N
              <span class="tooltiptext">TSMC's 4-nanometer (4nm) process node customised for NVIDIA.</span>
            </span>
          </td>
          <td colspan="3">
            <span class="tooltip">4NP
              <span class="tooltiptext">An enhanced version of TSMC's 4-nanometer (4nm) process with performance and efficiency improvements over the base 4N node. Used for the Blackwell generation GPUs.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">N3P (3NP)
              <span class="tooltiptext">TSMC's 3-nanometer (3nm) enhanced process node, offering significant density, performance, and efficiency advantages over 4nm nodes. Expected to be used for Rubin architecture GPUs.</span>
          </td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">Die configuration
              <span class="tooltiptext">The arrangement of silicon dies within the GPU package. A die is a small block of semiconducting material on which a circuit is fabricated. Modern high-performance GPUs often use multiple dies to achieve larger overall chip sizes than would be possible with single-die designs.</span>
            </span>
          </td>
          <td colspan="2">1 x GPU</td>
          <td colspan="3">2 x GPU</td>
          <td>2 x GPU, 2x I/O <span class="tooltip">chiplet <span class="tooltiptext">A small, modular piece of silicon used as a building block in modern chip design. Multiple chiplets combine in a single package to create larger processors while improving manufacturing yield and performance.</span></span></td>
          <td>4 x GPU, 2x I/O chiplet</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">FP4 PFLOPs
              <span class="tooltiptext">Floating-point performance measured in petaFLOPs (quadrillions of operations per second) using 4-bit precision (FP4).</span>
            </span>
          </td>
          <td colspan="2">4*</td>
          <td>10</td>
          <td>15</td>
          <td>4.6</td>
          <td>50</td>
          <td>100</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">HBM generation
              <span class="tooltiptext">High Bandwidth Memory, a specialised and ultra-fast memory component that is specifically designed for high-performance computing and AI workloads. It allows for faster data transfer and improved memory access, enabling efficient data processing and storage.</span>
            </span>
          </td>
          <td>HBM3</td>
          <td>HBM3E</td>
          <td>HBM3E</td>
          <td>HBM3E</td>
          <td>HBM3E</td>
          <td>
            <span class="tooltip">HBM4
              <span class="tooltiptext">Fourth generation HBM, offering higher capacity, bandwidth, and energy efficiency compared to HBM3E. Expected to debut with the Rubin architecture.</span>
            </span>
          </td>
          <td>
            <span class="tooltip">HBM4E
              <span class="tooltiptext">Enhanced version of HBM4 with higher capacity and bandwidth, allowing the VR300 GPU to have 1 TB of ultra-high-speed memory.</span>
            </span>
          </td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">HBM stacks
              <span class="tooltiptext">The number of individual memory die stacks in the GPU package. Each stack contains multiple layers of memory dies stacked vertically to increase capacity while maintaining a small footprint.
              </span>
            </span>
        </td>
          <td>5</td>
          <td>6</td>
          <td>8</td>
          <td>4</td>
          <td>8</td>
          <td colspan="2">16</td>
        </tr>
        
        <tr>
            <td>
              <span class="tooltip important">HBM capacity
                <span class="tooltiptext">The total amount of data that can be stored in memory at one time. Higher capacity allows AI systems to work with larger models and datasets without accessing slower storage.</span>
              </span>
            </td>
            <td>80 GB</td>
            <td>141 GB</td>
            <td>192 GB</td>
            <td>288 GB</td>
            <td>144 GB</td>
            <td>288 GB</td>
            <td>1,024 GB</td>
          </tr>

        <tr>
          <td>
            <span class="tooltip important">HBM bandwidth
              <span class="tooltiptext">The maximum data transfer rate between the GPU and its HBM, measured in terabytes per second (TB/s). Higher bandwidth allows the GPU to access data more quickly.</span>
            </span>
          </td>
          <td>3.35 TB/s</td>
          <td>4.8 TB/s</td>
          <td colspan="2">8 TB/s</td>
          <td>4 TB/s</td>
          <td>13 TB/s</td>
          <td>32 TB/s</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">Packaging
              <span class="tooltiptext">The technology used to integrate multiple semiconductor dies and components into a single package.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">CoWoS-S
              <span class="tooltiptext">Chip-on-Wafer-on-Substrate Standard. TSMC's advanced packaging technology that places chips on silicon interposers for high-bandwidth connectivity between GPU and HBM.</span>
            </span>
          </td>
          <td colspan="3">
            <span class="tooltip">CoWoS-L
              <span class="tooltiptext">Chip-on-Wafer-on-Substrate Large. An enhanced version of CoWoS that supports larger substrate areas, enabling integration of more chiplets and memory stacks.</span>
            </span>
          </td>
          <td colspan="2">CoWoS-L</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">SerDes speed
              <span class="tooltiptext">Serialiser/Deserialiser speed, measured in gigabits per second. Determines how fast data can be transmitted between the GPU and other components in the system.</span>
            </span>
          </td>
          <td colspan="2">112 Gb/s uni-di</td>
          <td colspan="3">224 Gb/s uni-di</td>
          <td>224 Gb/s uni-di</td>
          <td>224 Gb/s uni-di</td>
        </tr>
        
        <tr>
          <td>Nvidia CPU</td>
          <td colspan="2">
            <span class="tooltip">Grace
              <span class="tooltiptext">NVIDIA's first data center CPU, based on ARM architecture and named after computing pioneer Grace Hopper. Designed for AI, HPC, and data-intensive workloads.</span>
            </span>
          </td>
          <td colspan="3">Grace</td>
          <td colspan="2">
            <span class="tooltip">Vera
              <span class="tooltiptext">NVIDIA's next-generation CPU following Grace, named after astronomer Vera Rubin. Expected to offer significant performance and efficiency improvements.</span>
            </span>
          </td>
        </tr>
        
        <tr class="category-row">
          <td colspan="8">System Form Factor</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">Maximum system density
              <span class="tooltiptext">The highest number of GPUs that can be interconnected in a single system, defining the maximum computational capacity available for large-scale AI training and inference.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">NVL8
              <span class="tooltiptext">NVIDIA NVLink system with 8 GPUs in a single server node. Designed for high-performance AI and HPC workloads.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">NVL72
              <span class="tooltiptext">NVIDIA NVLink system with 72 GPUs across multiple nodes. 144 compute chiplets total (2 per GPU). Enables massive AI model training and inference.</span>
            </span>
          </td>
          <td>NVL16</td>
          <td>NVL144<br>144 compute chiplets, 72 GPUs</td>
          <td>
            <span class="tooltip">NVL576
              <span class="tooltiptext">NVIDIA's largest scale system with 576 compute chiplets across 144 GPUs. Designed for the most demanding AI and scientific computing workloads requiring exascale performance.</span>
            </span>
          </td>
        </tr>
        <tr>
          <td>
            <span class="tooltip">Form factor supported
                <span class="tooltiptext">The physical configuration and standardised design of the GPU system. Different form factors support various cooling, power, and interconnect requirements.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">HGX
              <span class="tooltiptext">NVIDIA's server platform for AI training and inference. A standardised board design that hosts multiple GPUs with NVLink interconnect.</span>
            </span>
          </td>
          <td colspan="3">
            <span class="tooltip">HGX, Oberon
              <span class="tooltiptext">Expanded form factor support including standard HGX and the Oberon platform, NVIDIA's liquid-cooled supercomputer architecture for multi-GPU systems.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">HGX, Oberon, Kyber
              <span class="tooltiptext">Full range of form factors including HGX, Oberon, and Kyber - NVIDIA's largest scale supercomputer architecture designed for exascale AI systems.</span>
            </span>
          </td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">Number of GPU packages
              <span class="tooltiptext">The total count of physical GPU packages (modules) in a system. Each package contains one or more GPU dies along with related components in a single unit that can be installed in a server.</span>
            </span>
          </td>
          <td colspan="2">8</td>
          <td>72</td>
          <td>72</td>
          <td>16</td>
          <td>72</td>
          <td>144</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">Number of GPU dies
              <span class="tooltiptext">The total count of individual GPU silicon chips across all packages in a system. This is calculated as the number of dies per chip multiplied by the number of packages.</span>
            </span>
          </td>
          <td colspan="2">8</td>
          <td>144</td>
          <td>144</td>
          <td>16</td>
          <td>144</td>
          <td>576</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip">Scale up links
              <span class="tooltiptext">The physical interconnect technology used to connect multiple GPUs together into a larger system. Higher bandwidth interconnects enable more efficient distributed computing across GPUs.</span>
            </span>
          </td>
          <td colspan="2">
            <span class="tooltip">UBB (PCB)
              <span class="tooltiptext">Ultra-Bandwidth Board, a PCB-based interconnect that provides high-speed connections between GPUs within a node.</span>
            </span>
          </td>
          <td>Copper Backplane</td>
          <td>UBB (PCB)</td>
          <td>Copper Backplane</td>
          <td colspan="2">PCB Backplane</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">Aggregate FP4 PFLOPs
              <span class="tooltiptext">Total compute performance of all GPUs in the system.</span>
            </span>
          </td>
          <td colspan="2">32*</td>
          <td>720</td>
          <td>1,080</td>
          <td>74</td>
          <td>3,600</td>
          <td>14,400</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">Aggregate HBM capacity
                <span class="tooltiptext">Total maximum memory storage of all GPUs in the system.</span>
            </span>
          </td>
          <td>14 TB</td>
          <td>14 TB</td>
          <td>14 TB</td>
          <td>21 TB</td>
          <td>64 TB</td>
          <td>21 TB</td>
          <td>147 TB</td>
        </tr>
        
        <tr>
          <td>
            <span class="tooltip important">Aggregate HBM bandwidth
                <span class="tooltiptext">Total memory bandwidth of all GPUs in the system.</span>
            </span>
          </td>
          <td>27 TB/s</td>
          <td>38 TB/s</td>
          <td>576 TB/s</td>
          <td>576 TB/s</td>
          <td>64 TB/s</td>
          <td>936 TB/s</td>
          <td>4,608 TB/s</td>
        </tr>
      </tbody>
    </table>
    
    <div class="source-citation">
      Source: Semianalysis - NVIDIA GTC 2025 â€“ Built For Reasoning, Vera Rubin, Kyber, CPO, Dynamo Inference, Jensen Math, Feynman.
      <a target="_blank" href="https://semianalysis.com/2025/03/19/nvidia-gtc-2025-built-for-reasoning-vera-rubin-kyber-cpo-dynamo-inference-jensen-math-feynman/">https://semianalysis.com/2025/03/19/nvidia-gtc-2025-built-for-reasoning-vera-rubin-kyber-cpo-dynamo-inference-jensen-math-feynman/</a>
    </div>
  </div>
  
  <script>
    // JavaScript for more advanced tooltip functionality
    document.addEventListener('DOMContentLoaded', function() {
      const tooltips = document.querySelectorAll('.tooltip');
      
      tooltips.forEach(tooltip => {
        tooltip.addEventListener('click', function(e) {
          e.preventDefault();
          e.stopPropagation();
          
          // Close all other open tooltips
          document.querySelectorAll('.tooltiptext.active').forEach(tt => {
            if (tt !== this.querySelector('.tooltiptext')) {
              tt.classList.remove('active');
            }
          });
          
          // Toggle this tooltip
          const tooltipText = this.querySelector('.tooltiptext');
          tooltipText.classList.toggle('active');
        });
      });
      
      // Close tooltips when clicking elsewhere
      document.addEventListener('click', function() {
        document.querySelectorAll('.tooltiptext.active').forEach(tt => {
          tt.classList.remove('active');
        });
      });
    });
  </script>
</body>
</html>